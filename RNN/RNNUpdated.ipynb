{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba966b69",
   "metadata": {},
   "source": [
    "# Reading Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59f4f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3362b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training.csv')\n",
    "label = pd.read_csv('label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b84cf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.42745072959635044, 1.0]</td>\n",
       "      <td>[0.4431369623068533, 1.0]</td>\n",
       "      <td>[0.45882319501735613, 1.0]</td>\n",
       "      <td>[0.48235313623987564, 0.9846379016807152]</td>\n",
       "      <td>[0.5058818931488647, 0.9846379016807152]</td>\n",
       "      <td>[0.5215681258593675, 0.9846379016807152]</td>\n",
       "      <td>[0.545098067081887, 0.9846379016807152]</td>\n",
       "      <td>[0.5607842997923899, 0.9846379016807152]</td>\n",
       "      <td>[0.568626823990876, 0.9846379016807152]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.3021271072523665, 0.8949215382418432]</td>\n",
       "      <td>[0.3446808182526158, 0.8949215382418432]</td>\n",
       "      <td>[0.3702120167680615, 0.8949215382418432]</td>\n",
       "      <td>[0.39574450038938713, 0.8949215382418432]</td>\n",
       "      <td>[0.43829821138963637, 0.9299476921612289]</td>\n",
       "      <td>[0.4553194387685601, 0.9299476921612289]</td>\n",
       "      <td>[0.4553194387685601, 0.8949215382418432]</td>\n",
       "      <td>[0.4553194387685601, 0.8598953843224575]</td>\n",
       "      <td>[0.4553194387685601, 0.7548142780830686]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.40969140138574034, 0.9672668768967665]</td>\n",
       "      <td>[0.41850261289738927, 0.9672668768967665]</td>\n",
       "      <td>[0.4361237055248678, 0.9508990796666634]</td>\n",
       "      <td>[0.48898698340730334, 0.9345337537935329]</td>\n",
       "      <td>[0.5066080760347819, 0.9345337537935329]</td>\n",
       "      <td>[0.5242291686622604, 0.9181659565634298]</td>\n",
       "      <td>[0.5242291686622604, 0.8526997103569628]</td>\n",
       "      <td>[0.5154179571506114, 0.7708681382773653]</td>\n",
       "      <td>[0.5154179571506114, 0.6890340948407951]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.3172687061175035, 0.5796835084861404]</td>\n",
       "      <td>[0.32530142400937295, 0.5796835084861404]</td>\n",
       "      <td>[0.34136564694124827, 0.5796835084861404]</td>\n",
       "      <td>[0.3574298698731236, 0.5796835084861404]</td>\n",
       "      <td>[0.38152681069686833, 0.5796835084861404]</td>\n",
       "      <td>[0.4136552565606189, 0.5971979076864492]</td>\n",
       "      <td>[0.4297194794924942, 0.5971979076864492]</td>\n",
       "      <td>[0.45381520746437554, 0.6147096624055259]</td>\n",
       "      <td>[0.46987943039625085, 0.6147096624055259]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[0.45023795040612585, 0.803920618642722]</td>\n",
       "      <td>[0.45971589079328723, 0.803920618642722]</td>\n",
       "      <td>[0.46919526246108706, 0.803920618642722]</td>\n",
       "      <td>[0.4976305149032096, 0.803920618642722]</td>\n",
       "      <td>[0.5165878269581707, 0.803920618642722]</td>\n",
       "      <td>[0.5260671986259705, 0.8217472404131104]</td>\n",
       "      <td>[0.5545024510680931, 0.8395738621834987]</td>\n",
       "      <td>[0.5639818227358929, 0.8573977923304884]</td>\n",
       "      <td>[0.5734597631230544, 0.8573977923304884]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          0  \\\n",
       "0           0                 [0.42745072959635044, 1.0]   \n",
       "1           1   [0.3021271072523665, 0.8949215382418432]   \n",
       "2           2  [0.40969140138574034, 0.9672668768967665]   \n",
       "3           3   [0.3172687061175035, 0.5796835084861404]   \n",
       "4           4   [0.45023795040612585, 0.803920618642722]   \n",
       "\n",
       "                                           1  \\\n",
       "0                  [0.4431369623068533, 1.0]   \n",
       "1   [0.3446808182526158, 0.8949215382418432]   \n",
       "2  [0.41850261289738927, 0.9672668768967665]   \n",
       "3  [0.32530142400937295, 0.5796835084861404]   \n",
       "4   [0.45971589079328723, 0.803920618642722]   \n",
       "\n",
       "                                           2  \\\n",
       "0                 [0.45882319501735613, 1.0]   \n",
       "1   [0.3702120167680615, 0.8949215382418432]   \n",
       "2   [0.4361237055248678, 0.9508990796666634]   \n",
       "3  [0.34136564694124827, 0.5796835084861404]   \n",
       "4   [0.46919526246108706, 0.803920618642722]   \n",
       "\n",
       "                                           3  \\\n",
       "0  [0.48235313623987564, 0.9846379016807152]   \n",
       "1  [0.39574450038938713, 0.8949215382418432]   \n",
       "2  [0.48898698340730334, 0.9345337537935329]   \n",
       "3   [0.3574298698731236, 0.5796835084861404]   \n",
       "4    [0.4976305149032096, 0.803920618642722]   \n",
       "\n",
       "                                           4  \\\n",
       "0   [0.5058818931488647, 0.9846379016807152]   \n",
       "1  [0.43829821138963637, 0.9299476921612289]   \n",
       "2   [0.5066080760347819, 0.9345337537935329]   \n",
       "3  [0.38152681069686833, 0.5796835084861404]   \n",
       "4    [0.5165878269581707, 0.803920618642722]   \n",
       "\n",
       "                                          5  \\\n",
       "0  [0.5215681258593675, 0.9846379016807152]   \n",
       "1  [0.4553194387685601, 0.9299476921612289]   \n",
       "2  [0.5242291686622604, 0.9181659565634298]   \n",
       "3  [0.4136552565606189, 0.5971979076864492]   \n",
       "4  [0.5260671986259705, 0.8217472404131104]   \n",
       "\n",
       "                                          6  \\\n",
       "0   [0.545098067081887, 0.9846379016807152]   \n",
       "1  [0.4553194387685601, 0.8949215382418432]   \n",
       "2  [0.5242291686622604, 0.8526997103569628]   \n",
       "3  [0.4297194794924942, 0.5971979076864492]   \n",
       "4  [0.5545024510680931, 0.8395738621834987]   \n",
       "\n",
       "                                           7  \\\n",
       "0   [0.5607842997923899, 0.9846379016807152]   \n",
       "1   [0.4553194387685601, 0.8598953843224575]   \n",
       "2   [0.5154179571506114, 0.7708681382773653]   \n",
       "3  [0.45381520746437554, 0.6147096624055259]   \n",
       "4   [0.5639818227358929, 0.8573977923304884]   \n",
       "\n",
       "                                           8  ...  168  169  170  171  172  \\\n",
       "0    [0.568626823990876, 0.9846379016807152]  ...  NaN  NaN  NaN  NaN  NaN   \n",
       "1   [0.4553194387685601, 0.7548142780830686]  ...  NaN  NaN  NaN  NaN  NaN   \n",
       "2   [0.5154179571506114, 0.6890340948407951]  ...  NaN  NaN  NaN  NaN  NaN   \n",
       "3  [0.46987943039625085, 0.6147096624055259]  ...  NaN  NaN  NaN  NaN  NaN   \n",
       "4   [0.5734597631230544, 0.8573977923304884]  ...  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "   173  174  175  176  177  \n",
       "0  NaN  NaN  NaN  NaN  NaN  \n",
       "1  NaN  NaN  NaN  NaN  NaN  \n",
       "2  NaN  NaN  NaN  NaN  NaN  \n",
       "3  NaN  NaN  NaN  NaN  NaN  \n",
       "4  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 179 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56cf5d9",
   "metadata": {},
   "source": [
    "# PyTorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a4f5255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/dolaameng/8918fefc05d0589f66279eab763d1e13\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfaa2058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6548, -0.8826],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "max_length = 3\n",
    "hidden_size = 2\n",
    "n_layers = 1\n",
    "\n",
    "# container\n",
    "batch_in = torch.zeros((batch_size, max_length, 1))\n",
    "\n",
    "#data\n",
    "vec_1 = torch.FloatTensor([[9, 2, 3]])\n",
    "vec_2 = torch.FloatTensor([[1, 2, 0]])\n",
    "vec_3 = torch.FloatTensor([[1, 0, 0]])\n",
    "\n",
    "batch_in[0] = vec_1.reshape(-1, 1)\n",
    "batch_in[1] = vec_2.reshape(-1, 1)\n",
    "batch_in[2] = vec_3.reshape(-1, 1)\n",
    "\n",
    "batch_in = Variable(batch_in)\n",
    "\n",
    "seq_lengths = [3,2,1]\n",
    "\n",
    "pack = torch.nn.utils.rnn.pack_padded_sequence(batch_in, seq_lengths, batch_first=True)\n",
    "\n",
    "# print(batch_in.size()) # >>> torch.Size([3, 3, 1])\n",
    "\n",
    "rnn = nn.RNN(1, hidden_size, n_layers, batch_first=True) \n",
    "h0 = Variable(torch.randn(n_layers, batch_size, hidden_size))\n",
    "\n",
    "out, _ = rnn(pack, h0)\n",
    "\n",
    "unpacked, unpacked_len = torch.nn.utils.rnn.pad_packed_sequence(out)\n",
    "\n",
    "# print(unpacked.size()) # >>> torch.Size([3, 3, 2])\n",
    "# print(unpacked_len) # >>> [3, 2, 1]\n",
    "print(unpacked[2, ...]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "206eed83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [3.]]), batch_sizes=tensor([3, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce6ce003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0169, -1.4825],\n",
       "         [ 0.9579, -0.7064],\n",
       "         [ 1.0794, -0.1054]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "377e6ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_map = ['chA', 'a', 'ai', 'bA', 'tA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2d379875",
   "metadata": {},
   "outputs": [],
   "source": [
    "label['label_index'] = label[['0']].applymap(lambda x: out_map.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "23b00124",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = label['label_index'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "18c8948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5e0a698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_data = OneHotEncoder(sparse=False)\n",
    "onehot_data = onehot_data.fit_transform(labels.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c7a6dffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345, 5)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8173bc2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d174575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82b0cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7310b4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = df.values[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f070d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inps = [torch.tensor([ast.literal_eval(i) for i in sample_i if type(i)==str]) for sample_i in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a1af353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_len_tuple = [(val, val.shape[0], labels[i]) for i,val in enumerate(inps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0bbd626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_inp_len_tuple = sorted(inp_len_tuple, key=lambda x: x[1], reverse=True)\n",
    "inputs = [i[0] for i in sorted_inp_len_tuple]\n",
    "seq_lens = [i[1] for i in sorted_inp_len_tuple]\n",
    "sorted_labels = [i[2] for i in sorted_inp_len_tuple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c32311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "72541eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inps = [[k for k in i] + ([[0,0]] * (max_seq_len - len(i))) for i in inps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e1a523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "40d12302",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_seq_batch = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "302a1610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packed_seq_batch = torch.nn.utils.rnn.pack_padded_sequence(padded_seq_batch, lengths=seq_lens, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f94bd6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "i = torch.randn(2, 3)\n",
    "output = m(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bb292a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3853,  1.0028,  1.0099],\n",
       "        [ 0.3264,  1.1759,  0.0283]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7d57cb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0437, 0.4764, 0.4799],\n",
       "        [0.2451, 0.5731, 0.1819]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "d3e82044",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_dim=178, output_dim=5):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, padded_seq_batch,seq_lens):\n",
    "        #x [sent length , batch size]\n",
    "        packed_seq_batch = torch.nn.utils.rnn.pack_padded_sequence(padded_seq_batch, lengths=seq_lens, batch_first=True)\n",
    "        # packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
    "        packed_output, hidden = self.rnn(packed_seq_batch)#[sentence length,batch size, hidden dim],[1,batch size,hidden dim]\n",
    "        # output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "1530e5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (rnn): RNN(2, 178)\n",
       "  (fc): Linear(in_features=178, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "fb23814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "cd461f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "4db8010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "0c9b9178",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b4d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "b6425409",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = [{'padded_seq_batch': padded_seq_batch, 'seq_lens': seq_lens, 'label': torch.Tensor(onehot_data)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "a3965b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([345, 5])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator[0]['label'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "25fbb95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch[\"padded_seq_batch\"], batch[\"seq_lens\"]).squeeze(1)\n",
    "        loss = criterion(predictions, batch[\"label\"])\n",
    "        acc = one_hot_accuracy(predictions, batch[\"label\"])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch[\"padded_seq_batch\"],batch[\"seq_lens\"]).squeeze(1)\n",
    "            loss = criterion(predictions, batch[\"label\"])\n",
    "            acc = one_hot_accuracy(predictions, batch[\"label\"])\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "10e19f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(e_l1):\n",
    "    e = np.exp(e_l1 - np.max(e_l1))\n",
    "    S = np.sum(e,axis=1)\n",
    "    P = e/np.expand_dims(S, 1)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "9c497ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_accuracy(predictions, onehot_data):\n",
    "    pred_list = [[float(p) for p in pred] for pred in predictions]\n",
    "    total_sum = np.sum(softmax(pred_list) * np.array(onehot_data), axis=1)\n",
    "    accuracy = sum(total_sum)/len(total_sum)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e72e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "4706f2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 1.613 | Train Acc: 20.01% | Val. Loss: 1.613 | Val. Acc: 20.01% |\n",
      "| Epoch: 02 | Train Loss: 1.613 | Train Acc: 20.01% | Val. Loss: 1.613 | Val. Acc: 20.01% |\n",
      "| Epoch: 03 | Train Loss: 1.613 | Train Acc: 20.01% | Val. Loss: 1.613 | Val. Acc: 20.01% |\n",
      "| Epoch: 04 | Train Loss: 1.613 | Train Acc: 20.01% | Val. Loss: 1.613 | Val. Acc: 20.01% |\n",
      "| Epoch: 05 | Train Loss: 1.613 | Train Acc: 20.01% | Val. Loss: 1.613 | Val. Acc: 20.01% |\n",
      "| Epoch: 06 | Train Loss: 1.613 | Train Acc: 20.01% | Val. Loss: 1.613 | Val. Acc: 20.01% |\n",
      "| Epoch: 07 | Train Loss: 1.613 | Train Acc: 20.01% | Val. Loss: 1.613 | Val. Acc: 20.01% |\n",
      "| Epoch: 08 | Train Loss: 1.613 | Train Acc: 20.01% | Val. Loss: 1.613 | Val. Acc: 20.01% |\n",
      "| Epoch: 09 | Train Loss: 1.613 | Train Acc: 20.01% | Val. Loss: 1.613 | Val. Acc: 20.01% |\n",
      "| Epoch: 10 | Train Loss: 1.613 | Train Acc: 20.01% | Val. Loss: 1.613 | Val. Acc: 20.01% |\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    train_loss, train_acc = train(model, iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, iterator, criterion)    \n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05fe195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085ede8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c938ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20eebe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b412c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1573bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=2, hidden_size=5, batch_first=True)\n",
    "output, (hn, cn) = lstm(packed_seq_batch.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec13164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fee795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "080b1190",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_output, output_lens = torch.nn.utils.rnn.pad_packed_sequence(output, batch_first=True, total_length=178)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea9912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18a9f7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([345, 178, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4898dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([345, 178, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d81646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749a2ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f059a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a2fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        #x = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        \n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        out = self.fc(hidden)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3649c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f474024",
   "metadata": {},
   "source": [
    "# Keras Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dc2f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4220b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d9230d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.42745072 1.        ]\n",
      "  [0.44313696 1.        ]\n",
      "  [0.4588232  1.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.3021271  0.89492154]\n",
      "  [0.34468082 0.89492154]\n",
      "  [0.37021202 0.89492154]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.4096914  0.96726686]\n",
      "  [0.4185026  0.96726686]\n",
      "  [0.4361237  0.95089906]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.560976   0.61965007]\n",
      "  [0.57073134 0.61965007]\n",
      "  [0.58048815 0.61965007]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.65898633 0.6557666 ]\n",
      "  [0.66820216 0.6385536 ]\n",
      "  [0.6774194  0.6385536 ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.5637854  0.6557666 ]\n",
      "  [0.5802462  0.6557666 ]\n",
      "  [0.58847725 0.6557666 ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "# raw_inputs = [\n",
    "#     [711.0, 632.9, 71],\n",
    "#     [73, 8, 3215, 55, 927],\n",
    "#     [83, 91, 1, 645, 1253, 927],\n",
    "# ]\n",
    "\n",
    "# By default, this will pad using 0s; it is configurable via the\n",
    "# \"value\" parameter.\n",
    "# Note that you could \"pre\" padding (at the beginning) or\n",
    "# \"post\" padding (at the end).\n",
    "# We recommend using \"post\" padding when working with RNN layers\n",
    "# (in order to be able to use the\n",
    "# CuDNN implementation of the layers).\n",
    "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    inps, padding=\"post\", dtype='float32'\n",
    ")\n",
    "print(padded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d72ec78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "        self.embedding = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)\n",
    "        self.lstm = layers.LSTM(32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        # Note that you could also prepare a `mask` tensor manually.\n",
    "        # It only needs to be a boolean tensor\n",
    "        # with the right shape, i.e. (batch_size, timesteps).\n",
    "        mask = self.embedding.compute_mask(inputs)\n",
    "        output = self.lstm(x, mask=mask)  # The layer will ignore the masked values\n",
    "        return output\n",
    "\n",
    "\n",
    "layer = MyLayer()\n",
    "x = np.random.random((32, 10)) * 100\n",
    "x = x.astype(\"int32\")\n",
    "# layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6f83219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 1s 2ms/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2199a159be0>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_neurons = 4\n",
    "nb_classes = 3\n",
    "embedding_size =10\n",
    "\n",
    "X = np.zeros((128, hidden_neurons), dtype=np.float32)\n",
    "y = np.zeros((128, nb_classes), dtype=np.int8)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(hidden_neurons, embedding_size))\n",
    "model.add(SimpleRNN(hidden_neurons, return_sequences=False)) \n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "model.fit(X, y, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db28257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = layers.Embedding(input_dim=len(padded_inputs), output_dim=5, mask_zero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44bad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_output = embedding(padded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "16304b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ True  True  True False False False]\n",
      " [ True  True  True  True  True False]\n",
      " [ True  True  True  True  True  True]], shape=(3, 6), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[ True  True  True False False False]\n",
      " [ True  True  True  True  True False]\n",
      " [ True  True  True  True  True  True]], shape=(3, 6), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "embedding = layers.Embedding(input_dim=5000, output_dim=5, mask_zero=True)\n",
    "masked_output = embedding(padded_inputs)\n",
    "\n",
    "print(masked_output._keras_mask)\n",
    "\n",
    "masking_layer = layers.Masking()\n",
    "# Simulate the embedding lookup by expanding the 2D input to 3D,\n",
    "# with embedding dimension of 10.\n",
    "unmasked_embedding = tf.cast(\n",
    "    tf.tile(tf.expand_dims(padded_inputs, axis=-1), [1, 1, 10]), tf.float32\n",
    ")\n",
    "\n",
    "masked_embedding = masking_layer(unmasked_embedding)\n",
    "print(masked_embedding._keras_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2861063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f1265a5",
   "metadata": {},
   "source": [
    "# Keras attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f31beaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e40974b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, SimpleRNN, Masking, Input, Activation\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import tensorflow.keras.utils as ku\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3708074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f9c943b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinates = np.random.random([10000, 50, 3]).astype(np.float32)\n",
    "# temps = np.random.rand(10000,50)\n",
    "\n",
    "# # ----- Define RNN model -----\n",
    "# rnn_model = tf.keras.Sequential()\n",
    "# rnn_model.add(tf.keras.layers.SimpleRNN(128))\n",
    "# rnn_model.add(tf.keras.layers.Dense(50))\n",
    "\n",
    "# # ----- Compile model -----\n",
    "# rnn_model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(1e-4))\n",
    "\n",
    "# ----- Train model -----\n",
    "# history = rnn_model.fit(x=coordinates, y=temps, batch_size=32,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13ed3403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 50, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c92db190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345, 178, 2)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "73dff597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/64276284/how-to-build-a-one-to-many-rnn-in-tensorflow\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(200))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7db282be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9bb29166",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_val = out['0'].unique()\n",
    "def _apply_index(x):\n",
    "    return list(unique_val).index(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b7ef14f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = out['0'].apply(lambda x: _apply_index(x)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "42eb4dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 5.2041 - accuracy: 0.1913\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 5.2041 - accuracy: 0.2464\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 5.2041 - accuracy: 0.2290\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 5.2041 - accuracy: 0.2000\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 5.2041 - accuracy: 0.1884\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=padded_inputs, y=y, batch_size=32,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b97ac8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_11 (SimpleRNN)    (None, 200)               40600     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 41,605\n",
      "Trainable params: 41,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c433134e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1998206 , 0.19999546, 0.19960669, 0.20000932, 0.20056786],\n",
       "       [0.19996426, 0.19967175, 0.19993274, 0.1999912 , 0.2004401 ],\n",
       "       [0.19982499, 0.20018087, 0.19972503, 0.19983442, 0.2004346 ],\n",
       "       ...,\n",
       "       [0.20011291, 0.19995978, 0.19973402, 0.19986778, 0.20032555],\n",
       "       [0.20048244, 0.20019385, 0.20017317, 0.20033269, 0.1988179 ],\n",
       "       [0.1999656 , 0.19973756, 0.19994004, 0.19998191, 0.2003749 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_inputs[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a002e9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cb34ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8ee32657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345, 178, 2)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1fe321",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(padded_inputs[:-5])\n",
    "true_test = model.predict(padded_input2[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbfb96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iteration_list,loss_list)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.title(\"Average error vs epoch.\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef813e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1_test=np.array(pred_test)\n",
    "pred1_test.shape\n",
    "true1_test=np.array(true_test)\n",
    "print(true1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4164f818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[55, 13, 2, 2, 5],\n",
       " [3, 46, 5, 4, 1],\n",
       " [7, 4, 32, 27, 6],\n",
       " [3, 6, 26, 34, 2],\n",
       " [2, 3, 8, 3, 55]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm_test=confusion_matrix(true1_test,pred1_test)\n",
    "print(cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba06c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
