{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dcbc259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "dec503e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conv_new2 import convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "6cc3b6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/rajeshr/Desktop/Group_22/selected/'\n",
    "\n",
    "images = []\n",
    "color_images = []\n",
    "label = []\n",
    "for i in os.listdir(path):\n",
    "    image = cv2.imread(path+i, cv2.IMREAD_GRAYSCALE)\n",
    "    color_image = cv2.imread(path+i, cv2.COLOR_BGR2RGB)\n",
    "    try:\n",
    "        images.append(cv2.resize(image, (224, 224)))\n",
    "        color_images.append(cv2.resize(color_image, (224, 224)))\n",
    "        label.append(i)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "images = np.array(images)\n",
    "label = np.array(label)\n",
    "color_images = np.array(color_images)\n",
    "labels = np.arange(0, len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "de914a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class kaiming_initialization:\n",
    "    \n",
    "    def initialize(self, n, size):\n",
    "        mean, sd = 0, np.sqrt(2/n)\n",
    "        weights = np.random.normal(mean, sd, size=size)\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "46303ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionLayer:\n",
    "    \n",
    "    def forward_prop(self, image, K, size, n):\n",
    "        output = []\n",
    "        ReLUout = []\n",
    "        filters = []\n",
    "        for i in range(K):\n",
    "            filtr = kaiming_initialization.initialize(kaiming_initialization, n, size)\n",
    "            filters.append(filtr)\n",
    "            res = convolution.convolve(convolution, inpt=image, filtr=filtr, stride = 1, padding = 0)\n",
    "            output.append(res)\n",
    "            ReLUout.append(ReLUActivation.forward_prop(ReLUActivation, res))\n",
    "            \n",
    "        self.output = np.array(output)\n",
    "        self.ReLUout = np.array(ReLUout)\n",
    "        self.filters = np.array(filters)\n",
    "        \n",
    "    def inputlayerConV(self, image, K, size, n):\n",
    "        output = []\n",
    "        ReLUout = []\n",
    "        filters = []\n",
    "        for i in range(K):\n",
    "            filtr = kaiming_initialization.initialize(kaiming_initialization, n, size)\n",
    "            filters.append(filtr)\n",
    "            res = convolution.inptconvolve(convolution, inpt=image, filtr=filtr, stride = 1, padding = 0)\n",
    "            output.append(res)\n",
    "            ReLUout.append(ReLUActivation.forward_prop(ReLUActivation, res))\n",
    "            \n",
    "        self.output = np.array(output)\n",
    "        self.ReLUout = np.array(ReLUout)\n",
    "        self.filters = np.array(filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "75472656",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool:\n",
    "    \n",
    "    def forward_prop(self, featureMaps, size, stride):\n",
    "        m, n = featureMaps[0].shape\n",
    "        fm, fn = size\n",
    "        result = []\n",
    "        poolout = []\n",
    "        for featureMap in featureMaps:\n",
    "            for i in range(0, m, stride):\n",
    "                for j in range(0, n, stride):\n",
    "                    if featureMap[i:i+fm, j:j+fn].shape == size:\n",
    "                        result.append(max(featureMap[i:i+fm, j:j+fn].flatten()))\n",
    "                        \n",
    "            Outm, Outn = int(((m-fm)/stride)+1), int(((n-fn)/stride)+1)\n",
    "            poolout.append(np.array(result).reshape((Outm, Outn)))\n",
    "            result = []\n",
    "        \n",
    "        self.maxpoolout = np.array(poolout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "26b6b2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLUActivation:\n",
    "    \n",
    "    def forward_prop(self, x):\n",
    "        \n",
    "        out = []\n",
    "        if len(x.shape) == 1:\n",
    "            for i in x:\n",
    "                if i>=0:\n",
    "                    out.append(i)\n",
    "                else:\n",
    "                    out.append(0)\n",
    "        else:\n",
    "            for i in x:\n",
    "                for j in i:\n",
    "                    if j>=0:\n",
    "                        out.append(j)\n",
    "                    else:\n",
    "                        out.append(0)\n",
    "                        \n",
    "        return np.array(out).reshape(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "70a6469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxActivation:\n",
    "    \n",
    "    def forward_prop(self, x):\n",
    "        x = np.array(x, dtype=np.float64)\n",
    "        exp = np.exp(x)\n",
    "        return exp/np.sum(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "6a95a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deepneuralnetwork:\n",
    "    \n",
    "    def forward_prop(self, xn, wh):\n",
    "        self.xn = xn\n",
    "        self.wh = wh\n",
    "        h1 = np.dot(wh.T, xn)\n",
    "        self.output = ReLUActivation.forward_prop(ReLUActivation, h1)\n",
    "\n",
    "    def Outforward_prop(self, xn, wo):\n",
    "        self.Oxn = xn\n",
    "        self.wo = wo\n",
    "        out = np.dot(wo.T, xn)\n",
    "        self.foutput = SoftmaxActivation.forward_prop(SoftmaxActivation, out)\n",
    "        \n",
    "    def flattenBackprop(self, dy):\n",
    "        if dy.shape[0] == self.xn.shape[0]:\n",
    "            dy = dy.T\n",
    "        dw = dy.dot(self.xn)\n",
    "        dx = np.dot(dy.T, self.wh.T)\n",
    "        self.wh -= 0.001 * dw.T\n",
    "        return dx\n",
    "        \n",
    "    def backprop(self, dy):\n",
    "        if dy.shape[0] == self.output.shape[0]:\n",
    "            dy = dy.T\n",
    "        dw = dy.dot(self.output)\n",
    "        dx = np.dot(dy.T, self.wh.T)\n",
    "        self.wh -= 0.001 * dw.T\n",
    "        return dx\n",
    "    \n",
    "    def Outbackprop(self, dy):\n",
    "        if dy.shape[0] == self.foutput.shape[0]:\n",
    "            dy = dy.T\n",
    "        dw = dy.dot(self.foutput)\n",
    "        dx = np.dot(dy.T, self.wo.T)\n",
    "        self.wo -= 0.001 * dw.T\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "0bf1e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flattening:\n",
    "    \n",
    "    def flatten(self, x):\n",
    "        self.flatten_out = x.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "b74a58ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class loss:\n",
    "    \n",
    "    def cross_entropy(self, inputs, labels):\n",
    "\n",
    "        out_num = labels.shape[0]\n",
    "        p = np.sum(labels.reshape(1,out_num)*inputs)\n",
    "        loss = -np.log(p)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "9f5da087",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = ConvolutionLayer()\n",
    "layer2 = MaxPool()\n",
    "layer3 = ConvolutionLayer()\n",
    "layer4 = MaxPool()\n",
    "layer5 = Flattening()\n",
    "layer6 = Deepneuralnetwork()\n",
    "layer7 = Deepneuralnetwork()\n",
    "kaiming = kaiming_initialization()\n",
    "losses = loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d928892",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 25\n",
    "\n",
    "for image in tr_data:\n",
    "    for i in range(epoch):\n",
    "        layer1.inputlayerConV(image, 32, (3, 3, 3), 27)\n",
    "        layer2.forward_prop(layer1.ReLUout, (2, 2), 1)\n",
    "        layer3.forward_prop(layer2.maxpoolout, 64, (32, 3, 3), 27)\n",
    "        layer4.forward_prop(layer3.ReLUout, (2, 2), 1)\n",
    "        layer5.flatten(layer4.maxpoolout)\n",
    "\n",
    "        wh = kaiming.initialize(layer5.flatten_out.shape[0]*128, (layer5.flatten_out.shape[0], 128))\n",
    "        wo = kaiming.initialize(128, (128, 3))\n",
    "        layer6.forward_prop(layer5.flatten_out, wh)\n",
    "        layer7.Outforward_prop(layer6.output, wo)\n",
    "        \n",
    "        acc = 0\n",
    "        total_acc = 0\n",
    "        labell = np.argmax(layer7.foutput)\n",
    "        entropyloss = losses.cross_entropy(layer7.foutput, labels)\n",
    "        if np.argmax(layer7.foutput) == np.argmax(labels):\n",
    "            acc += 1\n",
    "            total_acc += 1\n",
    "\n",
    "        dy = labels\n",
    "        \n",
    "        b_layer7 = layer7.Outbackprop(dy)\n",
    "        b_layer6 = layer6.backprop(b_layer7)\n",
    "        b_layer4 = layer4.backprop(b_layer6)\n",
    "        b_layer3 = layer3.backprop(b_layer3)\n",
    "        b_layer2 = layer2.backprop(b_layer2)\n",
    "        b_layer1 = layer1.backprop(b_layer1)\n",
    "        \n",
    "        print(\"Epoch: {} LOSS: {}, Accuracy: {}\".format(i+1, entropyloss, total_acc))\n",
    "        \n",
    "print(\"DATA TRAINED!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f25822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(image):\n",
    "    layer1.inputlayerConV(image, 32, (3, 3, 3), 27)\n",
    "    layer2.forward_prop(layer1.ReLUout, (2, 2), 1)\n",
    "    layer3.forward_prop(layer2.maxpoolout, 64, (32, 3, 3), 27)\n",
    "    layer4.forward_prop(layer3.ReLUout, (2, 2), 1)\n",
    "    layer5.flatten(layer4.maxpoolout)\n",
    "\n",
    "    wh = kaiming.initialize(layer5.flatten_out.shape[0]*128, (layer5.flatten_out.shape[0], 128))\n",
    "    wo = kaiming.initialize(128, (128, 3))\n",
    "    layer6.forward_prop(layer5.flatten_out, wh)\n",
    "    layer7.Outforward_prop(layer6.output, wo)\n",
    "\n",
    "    acc = 0\n",
    "    total_acc = 0\n",
    "    labell = np.argmax(layer7.foutput)\n",
    "    predicted = label1\n",
    "    entropyloss = losses.cross_entropy(layer7.foutput, labels)\n",
    "    if np.argmax(layer7.foutput) == np.argmax(labels):\n",
    "        acc += 1\n",
    "        total_acc += 1\n",
    "        \n",
    "    print(\"Epoch: {} Test LOSS: {}, Test Accuracy: {}\".format(i+1, entropyloss, total_acc))\n",
    "    \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bf1f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = test_model(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1270b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(test_label, p_class)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb686c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [layer1, layer2, layer3, layer4, layer5, layer6, layer7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b9249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model.layers #Conv layers at 0, 2\n",
    "filters, biases = model.layers[2].get_weights()\n",
    "print(layer[2].name, filters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37b97c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(64):\n",
    "    f = filters[:, :, :, i]\n",
    "    plt.imshow(f[:, :, 0], cmap='gray')\n",
    "    plt.savefig('/Users/rajeshr/Desktop/f/filters'+str(i+1)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989e6dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_index = [0] #[0, 1]\n",
    "outputs = [model.layers[i].output for i in conv_layer_index]\n",
    "model_short = Model(inputs=model.inputs, outputs=outputs)\n",
    "print(model_short.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e099b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('/Users/rajeshr/Desktop/Group_22/resized/chandelier.jpg', target_size=(224, 224))\n",
    "img = img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "feature_output = model_short.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac2644",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ftr in feature_output:\n",
    "    for i in range(32):\n",
    "        plt.imshow(ftr[:, :, i], cmap='gray') #ftr[0, :, :, i]\n",
    "        plt.savefig('/Users/rajeshr/Desktop/fm/fm'+str(i+1)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a7bb72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd12644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b282b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4175ba3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
