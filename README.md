# Deep-Learning
This repo contains the codes & reports written for the assignments in the course CS671 Deep Learning & Applications

### Perceptron & Fully Connected Neural Network - FCNN (Classification & Regression)

1) Implementation of Perceptron from scratch for classification tasks [view](https://github.com/Rajesh-Smartino/Deep-Learning/tree/main/Perceptron%20Regression)
2) Implementation of Fully Connected Neural Network (FCNN) with one hidden layer from scratch for classification tasks [view](https://github.com/Rajesh-Smartino/Deep-Learning/tree/main/FCNN%20Classification)
3) Implementation of Fully Connected Neural Network (FCNN) with two hidden layer from scratch for classification tasks [view](https://github.com/Rajesh-Smartino/Deep-Learning/tree/main/FCNN%20Classification)
4) Implementation of Perceptron from scratch for regression tasks [view](https://github.com/Rajesh-Smartino/Deep-Learning/tree/main/Perceptron%20Regression)
5) Implementation of Fully Connected Neural Network (FCNN) with one hidden layer from scratch for regression tasks [view](https://github.com/Rajesh-Smartino/Deep-Learning/tree/main/FCNN%20Regression)
6) Implementation of Fully Connected Neural Network (FCNN) with two hidden layer from scratch for regression tasks [view](https://github.com/Rajesh-Smartino/Deep-Learning/tree/main/FCNN%20Regression)

> Perceptron & FCNN Report [view](https://github.com/Rajesh-Smartino/Deep-Learning/blob/main/Report.pdf)

### Tasks using Handwritten digits (MNIST digit dataset) {Study of Various Optimizers}

1) FCNN with 3 hidden layers using cross entropy loss by stochastic gradient descent (SGD) algorithm [view](https://github.com/Rajesh-Smartino/Deep-Learning/blob/main/Optimizers/optimizers.ipynb)
2) FCNN with 3 hidden layers using cross entropy loss by vanilla gradient descent algorithm [view](https://github.com/Rajesh-Smartino/Deep-Learning/blob/main/Optimizers/optimizers.ipynb)
3) FCNN with 3 hidden layers using cross entropy loss by SGD with momentum (NAG) [view](https://github.com/Rajesh-Smartino/Deep-Learning/blob/main/Optimizers/optimizers.ipynb)
4) FCNN with 3 hidden layers using cross entropy loss by RMSProp algorithm [view](https://github.com/Rajesh-Smartino/Deep-Learning/blob/main/Optimizers/optimizers.ipynb)
5) FCNN with 3 hidden layers using cross entropy loss by Adam optimizer [view](https://github.com/Rajesh-Smartino/Deep-Learning/blob/main/Optimizers/optimizers.ipynb)

### Autoencoders

1) One hidden layer autoencoder for compression [view](https://github.com/Rajesh-Smartino/Deep-Learning/blob/main/Autoencoder/SingleHiddenLayer.ipynb)
2) Three hidden layer autoencoder for compression [view](https://github.com/Rajesh-Smartino/Deep-Learning/blob/main/Autoencoder/SingleHiddenLayer.ipynb)
3) One hidden layer autoencoder for classification task [view](https://github.com/Rajesh-Smartino/Deep-Learning/blob/main/Autoencoder/SingleHiddenLayer.ipynb)
4) Three hidden layer autoencoder for classification task [view](https://github.com/Rajesh-Smartino/Deep-Learning/blob/main/Autoencoder/SingleHiddenLayer.ipynb)
5) Denoising Autoencoder [view](https://github.com/Rajesh-Smartino/Deep-Learning/blob/main/Autoencoder/DenoisngAutoencoder.ipynb)

> Optimizers and Autoencoders Report [view](https://github.com/Rajesh-Smartino/Deep-Learning/blob/main/Report2.pdf)

### Convolutional Neural Network - CNN

1) 2 dimensional convolution (with zero padding & stride) from scratch [view](https://github.com/Rajesh-Smartino/Deep-Learning/blob/main/CNN%20from%20Scratch/Convolution.ipynb)
2) Building Convolutional Layers [view](https://github.com/its-rajesh/Deep-Learning/blob/main/CNN%20from%20Scratch/ConvolutionalLayer.ipynb)
3) Building Network and Backpropagation
4) Using Builtin functions 

> Convolutional Neural Network Report [view]()
