# -*- coding: utf-8 -*-
"""Autoencoder

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mLp-hbtIwoFBxBzWjl3gwduAnSnwa2Ni
    
author: Naisarg Pandya
"""

import numpy as np
from matplotlib import pyplot as plt
import pandas as pd
import os
import cv2
import tensorflow as tf
from tensorflow import keras

def read_data(path):

  train_path=path+"/train"
  test_path=path+"/test"
  validation_path=path+"/val"

  train_data,test_data,val_data = [],[],[]
  tr_out,test_out,val_out = [],[],[]
  
  for i in os.listdir(train_path):

      if i != ".DS_Store":
          for j in os.listdir(train_path+"/"+i):
              train_data.append(cv2.imread(train_path+"/"+i+"/"+j, cv2.IMREAD_GRAYSCALE))
              tr_out.append(i)

          for j in os.listdir(test_path+"/"+i):
              test_data.append(cv2.imread(test_path+"/"+i+"/"+j, cv2.IMREAD_GRAYSCALE))
              test_out.append(i)

          for j in os.listdir(validation_path+"/"+i):
              val_data.append(cv2.imread(validation_path+"/"+i+"/"+j, cv2.IMREAD_GRAYSCALE))
              val_out.append(i)
    
  train_data, test_data, val_data = np.array(train_data), np.array(test_data), np.array(val_data)
  tr_out, test_out, val_out = np.array(list(map(int, tr_out))), np.array(list(map(int, test_out))), np.array(list(map(int, val_out)))

  return train_data, test_data, val_data, tr_out, test_out, val_out

path  = "/content/drive/MyDrive/Group_22"
train_data,test_data,val_data,tr_out,test_out,val_out = read_data(path)

train_data = train_data/255
test_data = test_data/255
val_data = val_data/255

# Architechture for Autoencoder for one hidden layer with 64 neuron 
x_in = keras.Input(shape=(28,28,1),name="img")
x = keras.layers.Flatten()(x_in)
encoder_out = keras.layers.Dense(64,activation='sigmoid')(x)

# Encoder model for getting compressed representation of image
encoder1 = keras.Model(x_in,encoder_out,name="encoder")

decoder_ip = keras.layers.Dense(784,activation='sigmoid')(encoder_out)

decoder_op = keras.layers.Reshape((28,28,1))(decoder_ip)
optimizer = keras.optimizers.Adam(learning_rate = 0.01,decay = 1e-6)

# Autoencoder model for getting reconstructed image
Autoencoder1 = keras.Model(x_in,decoder_op,name="Autoencoder1")
Autoencoder1.summary()

# callback for define stopping criteria as consicutive difference between error is less that 0.0001
callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=3)

# compile the model for adam optimizer and accuracy matrics and loss as MSE
Autoencoder1.compile(optimizer,loss="mse",metrics=['accuracy'])
history = Autoencoder1.fit(train_data,train_data,epochs=100,batch_size=32,callbacks=[callback], validation_data=(val_data, val_data))
plt.plot(history.history['loss'])



plt.savefig("/content/drive/MyDrive/autoencoder_output/A1loss.png")



val_data.shape

# predict reconstructed image with use of Autoencoder model
model_op64 = Autoencoder1.predict([test_data[1].reshape(-1,28,28,1)])
#original Image from dataset
plt.imshow(test_data[1],cmap="gray")
plt.savefig("/content/drive/MyDrive/autoencoder_output/test_original1.png")

#reshape the vector into image
model_op64=model_op64.reshape(28,28)

# reconstructed image of original image which predicted by Autoencoder
plt.imshow(model_op64,cmap="gray")
plt.savefig("/content/drive/MyDrive/autoencoder_output/test_reconstruction1.png")

x_in = keras.Input(shape=(28,28,1),name="img")
x = keras.layers.Flatten()(x_in)
encoder_out = keras.layers.Dense(100,activation='sigmoid')(x)
encoder_2 = keras.Model(x_in,encoder_out,name="encoder")

decoder_ip = keras.layers.Dense(784,activation='sigmoid')(encoder_out)

decoder_op = keras.layers.Reshape((28,28,1))(decoder_ip)
optimizer = keras.optimizers.Adam(learning_rate = 0.01,decay = 1e-6)

Autoencoder2 = keras.Model(x_in,decoder_op,name="Autoencoder2")
Autoencoder2.summary()

callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=10)

Autoencoder2.compile(optimizer,loss="mse",metrics=['accuracy'])
history2 = Autoencoder2.fit(train_data,train_data,epochs=100,batch_size=32,callbacks=[callback],validation_data=(val_data, val_data))
#history_val = Autoencoder1.evaluate(val_data)
#print("test loss", history_val)

#history_val2 = Autoencoder2.fit(val_data,val_data,epochs=100,batch_size=32,callbacks=[callback])
plt.plot(history2.history['loss'])

plt.savefig("/content/drive/MyDrive/autoencoder_output/A2loss.png")

model_op100 = Autoencoder2.predict([test_data[1].reshape(-1,28,28,1)])
plt.imshow(test_data[1],cmap="gray")
plt.savefig("/content/drive/MyDrive/autoencoder_output/test_original_image2.png")

model_op100=model_op100.reshape(28,28)
plt.imshow(model_op100,cmap="gray")
plt.savefig("/content/drive/MyDrive/autoencoder_output/test_reconstructed_image2.png")

x_in = keras.Input(shape=(28,28,1),name="img")
x = keras.layers.Flatten()(x_in)
encoder_out = keras.layers.Dense(144,activation='sigmoid')(x)
encoder_3 = keras.Model(x_in,encoder_out,name="encoder_3")

decoder_ip = keras.layers.Dense(784,activation='sigmoid')(encoder_out)

decoder_op = keras.layers.Reshape((28,28,1))(decoder_ip)
optimizer = keras.optimizers.Adam(learning_rate = 0.01,decay = 1e-6)

Autoencoder3 = keras.Model(x_in,decoder_op,name="Autoencoder3")
Autoencoder3.summary()



callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=10)
Autoencoder3.compile(optimizer,loss="mse",metrics=['accuracy'])
history3 = Autoencoder3.fit(train_data,train_data,epochs=100,batch_size=32,callbacks=[callback],validation_data=(val_data, val_data))
#history_val3 = Autoencoder3.fit(val_data,val_data,epochs=100,batch_size=32,callbacks=[callback])
#compressed_rep_train = encoder_3.predict(train_data)
#compressed_rep_valid = encoder_3.predict(val_data)
#compressed_rep_test = encoder_3.predict(test_data)
plt.plot(history3.history['loss'])

plt.savefig("/content/drive/MyDrive/autoencoder_output/A3loss.png")

model_op144 = Autoencoder3.predict([test_data[1].reshape(-1,28,28,1)])
plt.imshow(test_data[1],cmap="gray")
plt.savefig("/content/drive/MyDrive/autoencoder_output/test_original_image.png")

model_op144=model_op144.reshape(28,28)
plt.imshow(model_op144,cmap="gray")
plt.savefig("/content/drive/MyDrive/autoencoder_output/test_reconstructed_image.png")

x_in = keras.Input(shape=(28,28,1),name="img")
x = keras.layers.Flatten()(x_in)
encoder_out = keras.layers.Dense(196,activation='sigmoid')(x)
encoder_4 = keras.Model(x_in,encoder_out,name="encoder_3")

decoder_ip = keras.layers.Dense(784,activation='sigmoid')(encoder_out)

decoder_op = keras.layers.Reshape((28,28,1))(decoder_ip)
optimizer = keras.optimizers.Adam(learning_rate = 0.01,decay = 1e-6)

Autoencoder4 = keras.Model(x_in,decoder_op,name="Autoencoder4")
Autoencoder4.summary()

callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=10)
Autoencoder4.compile(optimizer,loss="mse",metrics=['accuracy'])
history4 = Autoencoder4.fit(train_data,train_data,epochs=100,batch_size=32,callbacks=[callback],validation_data=(val_data, val_data))
#history_val3 = Autoencoder3.fit(val_data,val_data,epochs=100,batch_size=32,callbacks=[callback])
#compressed_rep_train = encoder_3.predict(train_data)
#compressed_rep_valid = encoder_3.predict(val_data)
#compressed_rep_test = encoder_3.predict(test_data)
plt.plot(history4.history['loss'])

plt.savefig("/content/drive/MyDrive/autoencoder_output/A41024loss.png")

model_op196 = Autoencoder4.predict([test_data[1].reshape(-1,28,28,1)])
plt.imshow(test_data[1],cmap="gray")
plt.savefig("/content/drive/MyDrive/autoencoder_output/1024test_original_image4.png")

model_op196=model_op196.reshape(28,28)
plt.imshow(model_op196,cmap="gray")
plt.savefig("/content/drive/MyDrive/autoencoder_output/1024test_reconstructed_image4.png")

x_in = keras.Input(shape=(28,28,1),name="img")
x = keras.layers.Flatten()(x_in)
encoder_out = keras.layers.Dense(256,activation='sigmoid')(x)
encoder_5 = keras.Model(x_in,encoder_out,name="encoder_3")

decoder_ip = keras.layers.Dense(784,activation='sigmoid')(encoder_out)

decoder_op = keras.layers.Reshape((28,28,1))(decoder_ip)
optimizer = keras.optimizers.Adam(learning_rate = 0.01,decay = 1e-6)

Autoencoder5 = keras.Model(x_in,decoder_op,name="Autoencoder5")
Autoencoder5.summary()

callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=10)
Autoencoder5.compile(optimizer,loss="mse",metrics=['accuracy'])
history5 = Autoencoder5.fit(train_data,train_data,epochs=100,batch_size=32,callbacks=[callback],validation_data=(val_data, val_data))
#history_val3 = Autoencoder3.fit(val_data,val_data,epochs=100,batch_size=32,callbacks=[callback])
#compressed_rep_train = encoder_3.predict(train_data)
#compressed_rep_valid = encoder_3.predict(val_data)
#compressed_rep_test = encoder_3.predict(test_data)
plt.plot(history5.history['loss'])

plt.savefig("/content/drive/MyDrive/autoencoder_output/A5loss.png")

model_op256 = Autoencoder5.predict([train_data[6500].reshape(-1,28,28,1)])
plt.imshow(train_data[6500],cmap="gray")
plt.savefig("/content/drive/MyDrive/autoencoder_output/test_org_image5train9.png")

model_op256 = model_op256.reshape(28,28)
plt.imshow(model_op256,cmap="gray")
plt.savefig("/content/drive/MyDrive/autoencoder_output/test_reconst_image5train9.png")

# To get compressed representation of image from train_data, val_dat, test_data for using that compressed representation in classifiction.
encoder_train5 = encoder_5.predict([train_data.reshape(-1,28,28,1)])
encoder_val5 = encoder_5.predict([val_data.reshape(-1,28,28,1)])
encoder_test5 = encoder_5.predict([test_data.reshape(-1,28,28,1)])

print(encoder_train5.shape)
print(encoder_val5.shape)
print(encoder_test5.shape)

# Model of FCNN with 3 hidden layers for classification 
model51 = tf.keras.models.Sequential([
    #tf.keras.layers.Flatten(input_shape=(28, 28), name='Input_Layer'),
    tf.keras.layers.Dense(361, activation='sigmoid', name='Hidden_Layer_1'),
    tf.keras.layers.Dense(289, activation='sigmoid', name='Hidden_Layer_2'),
    tf.keras.layers.Dense(361, activation='sigmoid', name='Hidden_Layer_3'),
    tf.keras.layers.Dense(10, activation='softmax', name='Output_Layer')
])
optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-08,
    name='Adam')
model51.compile(optimizer=optimizer,
             loss='sparse_categorical_crossentropy',
             metrics=['accuracy'])
callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=10)
trained = model51.fit(encoder_train5, tr_out, epochs=10000, callbacks=callback)

# For getting validation loss and accuracy.
loss, mse = model51.evaluate(encoder_val5, val_out)

# confusion matrix for best architecture 
from sklearn.metrics import confusion_matrix
prediction_test = model51.predict(encoder_test5)
prdicted_value = [np.argmax(label) for label in prediction_test]
cm = confusion_matrix(test_out,prdicted_value)
print(cm)

#For getting loss and accuracy for testing
loss, mse = model51.evaluate(encoder_test5, test_out)

model52 = tf.keras.models.Sequential([
    #tf.keras.layers.Flatten(input_shape=(28, 28), name='Input_Layer'),
    tf.keras.layers.Dense(289, activation='sigmoid', name='Hidden_Layer_1'),
    tf.keras.layers.Dense(256, activation='sigmoid', name='Hidden_Layer_2'),
    tf.keras.layers.Dense(289, activation='sigmoid', name='Hidden_Layer_3'),
    tf.keras.layers.Dense(10, activation='softmax', name='Output_Layer')
])
optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-08,
    name='Adam')
model52.compile(optimizer=optimizer,
             loss='sparse_categorical_crossentropy',
             metrics=['accuracy'])
callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=10)
trained = model52.fit(encoder_train5, tr_out, epochs=10000, callbacks=callback)
loss, mse = model52.evaluate(encoder_val5, val_out)

model53 = tf.keras.models.Sequential([
    #tf.keras.layers.Flatten(input_shape=(28, 28), name='Input_Layer'),
    tf.keras.layers.Dense(400, activation='sigmoid', name='Hidden_Layer_1'),
    tf.keras.layers.Dense(256, activation='sigmoid', name='Hidden_Layer_2'),
    tf.keras.layers.Dense(400, activation='sigmoid', name='Hidden_Layer_3'),
    tf.keras.layers.Dense(10, activation='softmax', name='Output_Layer')
])
optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-08,
    name='Adam')
model53.compile(optimizer=optimizer,
             loss='sparse_categorical_crossentropy',
             metrics=['accuracy'])
callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=10)
trained = model53.fit(encoder_train5, tr_out, epochs=10000, callbacks=callback)
loss, mse = model53.evaluate(encoder_val5, val_out)

# For getting weight between input and hidden layer
weight1 = Autoencoder5.layers[2].get_weights()
weight1[0].shape

w1 = []
# each weight matrix size will be 781 X 1 so it will convert into 28 X 28 for weight visulization 
for w in weight1[0].T:
    w1.append(w.reshape(28, 28))
    
w1 = np.array(w1)
w1.shape

# For weight visulization of any random 9 neuron out of 256 neuron weight matrices
n = 9
plt.figure(figsize=(25, 25))
for i in range(n):
    k = np.random.randint(0, 256)
    ax = plt.subplot(3, 3, i+1)
    plt.title("Node no: "+str(k))
    plt.imshow(w1[k], cmap='gray')
    plt.savefig("/content/drive/MyDrive/autoencoder_output/weight_img5"+str(np.random.randint(1, 100000))+".png")
plt.show

x_in = keras.Input(shape=(28,28,1),name="img")
x = keras.layers.Flatten()(x_in)
encoder_out311 = keras.layers.Dense(144,activation='sigmoid')(x)
encoder311 = keras.Model(x_in,encoder_out311,name="encoder1")

encoder_out312 = keras.layers.Dense(100,activation='sigmoid')(encoder_out311)
encoder312 = keras.Model(x_in,encoder_out312,name="encoder312")

decoder_ip310 = keras.layers.Dense(144,activation='sigmoid')(encoder_out312)

decoder_ip311 = keras.layers.Dense(784,activation='sigmoid')(decoder_ip310)

decoder_op312 = keras.layers.Reshape((28,28,1))(decoder_ip311)
optimizer = keras.optimizers.Adam(learning_rate = 0.01,decay = 1e-6)

Autoencoder31 = keras.Model(x_in,decoder_op312,name="Autoencoder31")
Autoencoder31.summary()

callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=10)
Autoencoder31.compile(optimizer,loss="mse",metrics=['accuracy'])
history31 = Autoencoder31.fit(train_data,train_data,epochs=100,batch_size=32,callbacks=[callback],validation_data=(val_data, val_data))
#history_val31 = Autoencoder31.fit(val_data,val_data,epochs=100,batch_size=32,callbacks=[callback])
plt.plot(history31.history['loss'])

plt.savefig("/content/drive/MyDrive/autoencoder_output/A31loss.png")

encoder_op311 = encoder311.predict([test_data[1].reshape(-1,28,28,1)])
#plt.imshow(encoder_op311.reshape(12,12),cmap="gray")

encoder_train311 = encoder311.predict([train_data.reshape(-1,28,28,1)])
#encoder_train1= encoder_train1.reshape(8,8)
encoder_val311 = encoder311.predict([val_data.reshape(-1,28,28,1)])
#encoder_val1 = encoder_val1.reshape(8,8)
encoder_test311 = encoder311.predict([test_data.reshape(-1,28,28,1)])
#encoder_val1 = encoder_test1.reshape(8,8)
print(encoder_train311.shape)
print(encoder_val311.shape)
print(encoder_test311.shape)

model311 = tf.keras.models.Sequential([
    #tf.keras.layers.Flatten(input_shape=(28, 28), name='Input_Layer'),
    tf.keras.layers.Dense(289, activation='sigmoid', name='Hidden_Layer_1'),
    tf.keras.layers.Dense(256, activation='sigmoid', name='Hidden_Layer_2'),
    tf.keras.layers.Dense(289, activation='sigmoid', name='Hidden_Layer_3'),
    tf.keras.layers.Dense(10, activation='softmax', name='Output_Layer')
])
optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-08,
    name='Adam')
model311.compile(optimizer=optimizer,
             loss='sparse_categorical_crossentropy',
             metrics=['accuracy'])
callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=10)
trained311 = model311.fit(encoder_train311, tr_out, epochs=10000, callbacks=callback)
loss, mse = model311.evaluate(encoder_val311, val_out)

from sklearn.metrics import confusion_matrix
prediction_test311 = model311.predict(encoder_test311)
prdicted_value311 = [np.argmax(label) for label in prediction_test311]
cm31 = confusion_matrix(test_out,prdicted_value311)
print(cm31)

loss, mse = model311.evaluate(encoder_test311, test_out)

model312 = tf.keras.models.Sequential([
    #tf.keras.layers.Flatten(input_shape=(28, 28), name='Input_Layer'),
    tf.keras.layers.Dense(361, activation='sigmoid', name='Hidden_Layer_1'),
    tf.keras.layers.Dense(289, activation='sigmoid', name='Hidden_Layer_2'),
    tf.keras.layers.Dense(361, activation='sigmoid', name='Hidden_Layer_3'),
    tf.keras.layers.Dense(10, activation='softmax', name='Output_Layer')
])
optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-08,
    name='Adam')
model312.compile(optimizer=optimizer,
             loss='sparse_categorical_crossentropy',
             metrics=['accuracy'])
callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=10)
trained = model312.fit(encoder_train311, tr_out, epochs=10000, callbacks=callback)
loss, mse = model312.evaluate(encoder_val311, val_out)

model313 = tf.keras.models.Sequential([
    #tf.keras.layers.Flatten(input_shape=(28, 28), name='Input_Layer'),
    tf.keras.layers.Dense(400, activation='sigmoid', name='Hidden_Layer_1'),
    tf.keras.layers.Dense(256, activation='sigmoid', name='Hidden_Layer_2'),
    tf.keras.layers.Dense(400, activation='sigmoid', name='Hidden_Layer_3'),
    tf.keras.layers.Dense(10, activation='softmax', name='Output_Layer')
])
optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-08,
    name='Adam')
model313.compile(optimizer=optimizer,
             loss='sparse_categorical_crossentropy',
             metrics=['accuracy'])
callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=10)
trained = model313.fit(encoder_train311, tr_out, epochs=10000, callbacks=callback)
loss, mse = model313.evaluate(encoder_val311, val_out)

weight31 = Autoencoder31.layers[2].get_weights()
weight31[0].shape

w31 = []

for w in weight31[0].T:
    w31.append(w.reshape(28, 28))
    
w31 = np.array(w31)
w31.shape

n = 9
plt.figure(figsize=(25, 25))
for i in range(n):
    k = np.random.randint(0, 144)
    ax = plt.subplot(3, 3, i+1)
    plt.title("Node no: "+str(k))
    plt.imshow(w31[k], cmap='gray')
    plt.savefig("/content/drive/MyDrive/autoencoder_output/weight_img31"+str(np.random.randint(1, 100000))+".png")
plt.show

encoder_op312 = encoder312.predict([test_data[1].reshape(-1,28,28,1)])
#plt.imshow(encoder_op312.reshape(10,10),cmap="gray")

model_op31 = Autoencoder31.predict([test_data[3500].reshape(-1,28,28,1)])
plt.imshow(test_data[3500],cmap="gray")
plt.savefig("/content/drive/MyDrive/autoencoder_output/31train_org_image3500.png")

model_op31=model_op31.reshape(28,28)
plt.imshow(model_op31,cmap="gray")
plt.savefig("/content/drive/MyDrive/autoencoder_output/31train_reconst_image3500.png")

x_in = keras.Input(shape=(28,28,1),name="img")
x = keras.layers.Flatten()(x_in)
encoder_out321 = keras.layers.Dense(100,activation='sigmoid')(x)
encoder321 = keras.Model(x_in,encoder_out321,name="encoder321")

encoder_out322 = keras.layers.Dense(64,activation='sigmoid')(encoder_out321)
encoder322 = keras.Model(x_in,encoder_out322,name="encoder322")

decoder_ip320 = keras.layers.Dense(100,activation='sigmoid')(encoder_out322)

decoder_ip321 = keras.layers.Dense(784,activation='sigmoid')(decoder_ip320)

decoder_op322 = keras.layers.Reshape((28,28,1))(decoder_ip321)
optimizer = keras.optimizers.Adam(learning_rate = 0.01,decay = 1e-6)

Autoencoder32 = keras.Model(x_in,decoder_op322,name="Autoencoder32")
Autoencoder32.summary()

callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=10)
Autoencoder32.compile(optimizer,loss="mse",metrics=['accuracy'])
history32 = Autoencoder32.fit(train_data,train_data,epochs=100,batch_size=32,callbacks=[callback],validation_data=(val_data, val_data))
history_val32 = Autoencoder32.fit(train_data,train_data,epochs=100,batch_size=32,callbacks=[callback])
plt.plot(history32.history['loss'])

plt.savefig("/content/drive/MyDrive/autoencoder_output/A32loss.png")



model_op31 = Autoencoder31.predict([test_data[1].reshape(-1,28,28,1)])
plt.imshow(test_data[1],cmap="gray")
plt.savefig("/content/drive/MyDrive/autoencoder_output/test_original_image.png")

model_op31=model_op31.reshape(28,28)
plt.imshow(model_op31,cmap="gray")
plt.savefig("/content/drive/MyDrive/autoencoder_output/test_reconstructed_image.png")

x_in = keras.Input(shape=(28,28,1),name="img")
x = keras.layers.Flatten()(x_in)
encoder_out332 = keras.layers.Dense(225,activation='sigmoid')(x)
encoder332 = keras.Model(x_in,encoder_out332,name="encoder332")

encoder_out332 = keras.layers.Dense(64,activation='sigmoid')(encoder_out332)
encoder332 = keras.Model(x_in,encoder_out332,name="encoder332")

decoder_ip330 = keras.layers.Dense(225,activation='sigmoid')(encoder_out332)

decoder_ip331 = keras.layers.Dense(784,activation='sigmoid')(decoder_ip330)

decoder_op332 = keras.layers.Reshape((28,28,1))(decoder_ip331)
optimizer = keras.optimizers.Adam(learning_rate = 0.01,decay = 1e-6)

Autoencoder33 = keras.Model(x_in,decoder_op332,name="Autoencoder33")
Autoencoder33.summary()

callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=10)
Autoencoder33.compile(optimizer,loss="mse",metrics=['accuracy'])
history33 = Autoencoder33.fit(train_data,train_data,epochs=100,batch_size=32,callbacks=[callback],validation_data=(val_data, val_data))
#history_val33 = Autoencoder33.fit(train_data,train_data,epochs=100,batch_size=32,callbacks=[callback])
plt.plot(history33.history['loss'])

plt.savefig("/content/drive/MyDrive/autoencoder_output/A33loss.png")

model_op33 = Autoencoder33.predict([test_data[1].reshape(-1,28,28,1)])
plt.imshow(test_data[1],cmap="gray")
plt.savefig("/content/drive/MyDrive/autoencoder_output/test_original_image33.png")

model_op33=model_op33.reshape(28,28)
plt.imshow(model_op33,cmap="gray")
plt.savefig("/content/drive/MyDrive/autoencoder_output/test_reconstructed_image33.png")

x_in = keras.Input(shape=(28,28,1),name="img")
x = keras.layers.Flatten()(x_in)
encoder_out341 = keras.layers.Dense(256,activation='sigmoid')(x)
encoder341 = keras.Model(x_in,encoder_out341,name="encoder341")

encoder_out342 = keras.layers.Dense(100,activation='sigmoid')(encoder_out341)
encoder342 = keras.Model(x_in,encoder_out342,name="encoder342")

decoder_ip330 = keras.layers.Dense(256,activation='sigmoid')(encoder_out342)

decoder_ip331 = keras.layers.Dense(784,activation='sigmoid')(decoder_ip330)

decoder_op332 = keras.layers.Reshape((28,28,1))(decoder_ip331)
optimizer = keras.optimizers.Adam(learning_rate = 0.01,decay = 1e-6)

Autoencoder34 = keras.Model(x_in,decoder_op332,name="Autoencoder34")
Autoencoder34.summary()

callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=10)
Autoencoder34.compile(optimizer,loss="mse",metrics=['accuracy'])
history34 = Autoencoder34.fit(train_data,train_data,epochs=100,batch_size=32,callbacks=[callback],validation_data=(val_data, val_data))
#history_val33 = Autoencoder33.fit(train_data,train_data,epochs=100,batch_size=32,callbacks=[callback])
plt.plot(history34.history['loss'])

plt.savefig("/content/drive/MyDrive/autoencoder_output/A34loss.png")



model_op34 = Autoencoder34.predict([test_data[1].reshape(-1,28,28,1)])
plt.imshow(test_data[1],cmap="gray")
plt.savefig("D:\Autoencoder_op\test_original_image34.png")

model_op34=model_op34.reshape(28,28)
plt.imshow(model_op34,cmap="gray")
plt.savefig("D:\Autoencoder_op\test_reconstructed_image34.png")

x_in = keras.Input(shape=(28,28,1),name="img")
x = keras.layers.Flatten()(x_in)
encoder_out351 = keras.layers.Dense(324,activation='sigmoid')(x)
encoder351 = keras.Model(x_in,encoder_out351,name="encoder332")

encoder_out352 = keras.layers.Dense(144,activation='sigmoid')(encoder_out351)
encoder352 = keras.Model(x_in,encoder_out352,name="encoder332")

decoder_ip330 = keras.layers.Dense(324,activation='sigmoid')(encoder_out352)

decoder_ip331 = keras.layers.Dense(784,activation='sigmoid')(decoder_ip330)

decoder_op332 = keras.layers.Reshape((28,28,1))(decoder_ip331)
optimizer = keras.optimizers.Adam(learning_rate = 0.01,decay = 1e-6)

Autoencoder35 = keras.Model(x_in,decoder_op332,name="Autoencoder35")
Autoencoder35.summary()

callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=10)
Autoencoder35.compile(optimizer,loss="mse",metrics=['accuracy'])
history35 = Autoencoder35.fit(train_data,train_data,epochs=100,batch_size=32,callbacks=[callback],validation_data=(val_data, val_data))
#history_val33 = Autoencoder33.fit(train_data,train_data,epochs=100,batch_size=32,callbacks=[callback])
plt.plot(history35.history['loss'])

plt.savefig("D:\Autoencoder_op\A35loss.png")

model_op35 = Autoencoder35.predict([test_data[1].reshape(-1,28,28,1)])
plt.imshow(test_data[1],cmap="gray")
plt.savefig("D:\Autoencoder_op\test_original_image35.png")

model_op35=model_op35.reshape(28,28)
plt.imshow(model_op35,cmap="gray")
plt.savefig("D:\Autoencoder_op\test_reconstructed_image35.png")

