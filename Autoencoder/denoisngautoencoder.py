# -*- coding: utf-8 -*-
"""DenoisngAutoencoder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZC4kHsikYjt5cNBXN_5xL_2L2flLqkb_

# Denoising Autoencoder
"""

import numpy as np
from matplotlib import pyplot as plt
import pandas as pd
import os
import cv2
import zipfile as zip

import tensorflow as tf
import numpy as np

"""### Reading data as image and storing it into training, validation and testing"""

def read_data(path):
    
    train_path = path+"/train"
    test_path = path+"/test"
    validation_path = path+"/val"
    
    tr_data, test_data, val_data = [], [], []
    tr_out, test_out, val_out = [], [], []

    for i in os.listdir(train_path):

        if i != ".DS_Store":
            for j in os.listdir(train_path+"/"+i):
                tr_data.append(cv2.imread(train_path+"/"+i+"/"+j, cv2.IMREAD_GRAYSCALE))
                tr_out.append(i)

            for j in os.listdir(test_path+"/"+i):
                test_data.append(cv2.imread(test_path+"/"+i+"/"+j, cv2.IMREAD_GRAYSCALE))
                test_out.append(i)

            for j in os.listdir(validation_path+"/"+i):
                val_data.append(cv2.imread(validation_path+"/"+i+"/"+j, cv2.IMREAD_GRAYSCALE))
                val_out.append(i)
                
                
    tr_data, test_data, val_data = np.array(tr_data), np.array(test_data), np.array(val_data)
    tr_out, test_out, val_out = np.array(list(map(int, tr_out))), np.array(list(map(int, test_out))), np.array(list(map(int, val_out)))

    return tr_data, test_data, val_data, tr_out, test_out, val_out

from google.colab import drive
drive.mount('/content/drive')

folder = zip.ZipFile("/content/drive/MyDrive/Group_22.zip",'r')
folder.extractall("content/drive/MyDrive/G22")

path = "/content/content/drive/MyDrive/G22/Group_22"
tr_data, test_data, val_data, tr_out, test_out, val_out = read_data(path)

plt.imshow(tr_data[0])

"""# Noisy autoencoder single hidden layer model"""

tr_data = tr_data.astype('float32') / 255.
test_data = test_data.astype('float32') / 255.

tr_data = tr_data[..., tf.newaxis]
test_data = test_data[..., tf.newaxis]

print(tr_data.shape)

noise_factor = 0.2
noisy_tr = tr_data + noise_factor * tf.random.normal(shape=tr_data.shape) 
noisy_test = test_data + noise_factor * tf.random.normal(shape=test_data.shape) 

noisy_tr = tf.clip_by_value(noisy_tr, clip_value_min=0., clip_value_max=1.)
noisy_test = tf.clip_by_value(noisy_test, clip_value_min=0., clip_value_max=1.)

n = 10
plt.figure(figsize=(20, 2))
for i in range(n):
    k = np.random.randint(1, 3500)
    ax = plt.subplot(1, n, i+1)
    plt.title("Input + Noise")
    plt.imshow(tf.squeeze(noisy_test[k]), cmap='gray')
plt.show()

"""### Generating Model"""

class NoisyAutoencoder(tf.keras.models.Model):
  
    def __init__(self):
        
        super(NoisyAutoencoder, self).__init__()
        
        self.encoder = tf.keras.Sequential([
          tf.keras.layers.Flatten(input_shape=(28, 28), name='Input_Layer'),
          tf.keras.layers.Dense(256, activation='sigmoid', name='Hidden_Layer_1')])

        self.decoder = tf.keras.Sequential([
            tf.keras.layers.Dense(784, activation='sigmoid', name='Output_Layer'),
            tf.keras.layers.Reshape((28, 28))])
          

    def call(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

noisyautoenoder = NoisyAutoencoder()

noisyautoenoder.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())

callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=3)
trained = noisyautoenoder.fit(noisy_tr, tr_data, epochs=10000, batch_size=1, callbacks=callback)

'''
noisyautoenoder.fit(noisy_tr, tr_data,
                epochs=10,
                shuffle=True,
                validation_data=(noisy_test, test_data))
'''

#Plotting error vs epoch graph
plt.plot(trained.history['loss'])
plt.title("Average Training Error Vs Epoch")
plt.xlabel("epochs")
plt.ylabel("Average error")
#plt.savefig("/Users/rajeshr/Desktop/errorvsepoch"+str(np.random.randint(1, 100000))+".png")
plt.show()

noisyautoenoder.encoder.summary()
noisyautoenoder.decoder.summary()

encoded_imgs = noisyautoenoder.encoder(noisy_test).numpy()
decoded_imgs = noisyautoenoder.decoder(encoded_imgs).numpy()

k = np.random.randint(1, 3500)

plt.subplot(1, 2, 1)
plt.title("Input+noise")
plt.imshow(tf.squeeze(noisy_test[k]), cmap='gray')

plt.subplot(1, 2, 2)
plt.title("Reconstructed")
plt.imshow(tf.squeeze(decoded_imgs[k]), cmap='gray')

#plt.savefig("/Users/rajeshr/Desktop/output"+str(np.random.randint(1, 100000))+".png")
plt.show()

"""### Weight visualization"""

from keras import get_activations, display_activations

input_sample = test_data[:1]

activations = get_activations(encoder, input_sample)
display_activations(activations, cmap="gray", save=False)





weight1 = noisyautoenoder.layers[0].get_weights()
weight1[0].shape
#weight1

weight2 = noisyautoenoder.layers[1].get_weights()
weight2[0].shape

w1 = []

for w in weight1[0].T:
    w1.append(w.reshape(28, 28))
    
w1 = np.array(w1)
w1.shape

n = 9
plt.figure(figsize=(25, 25))
for i in range(n):
    k = np.random.randint(0, 256)
    ax = plt.subplot(3, 3, i+1)
    plt.title("Node no: "+str(k))
    plt.imshow(w1[k], cmap='gray')
    
#plt.savefig("/Users/rajeshr/Desktop/weightvisualization"+str(np.random.randint(1, 100000))+".png")
plt.show()

w2 = []

for w in weight2[0]:
    w2.append(w.reshape(28, 28))
    
w2 = np.array(w2)
w2.shape

n = 9
plt.figure(figsize=(25, 25))
for i in range(n):
    k = np.random.randint(0, 256)
    ax = plt.subplot(3, 3, i+1)
    plt.title("Node no: "+str(k))
    plt.imshow(w2[k])
    
#plt.savefig("/Users/rajeshr/Desktop/weightvisualization"+str(np.random.randint(1, 100000))+".png")
plt.show()

"""### Classification"""

encoded_tr = noisyautoenoder.encoder(noisy_tr).numpy()
decoded_tr = noisyautoenoder.decoder(encoded_imgs).numpy()
from tensorflow.keras.utils import  to_categorical

encoded_val=noisyautoenoder.encoder(val_data).numpy()

y_train=to_categorical(tr_out)
y_val=to_categorical(val_out)
y_test=to_categorical(test_out)

"""classifier"""

encoded_tr_1 = noisyautoenoder.encoder(tr_data).numpy()



classifier = tf.keras.models.Sequential([
    #tf.keras.layers.Flatten(input_shape=(28, 28), name='Input_Layer'),
    tf.keras.layers.Dense(1024, activation='sigmoid', name='Hidden_Layer_1'),
    tf.keras.layers.Dense(512, activation='sigmoid', name='Hidden_Layer_2'),
    tf.keras.layers.Dense(256, activation='sigmoid', name='Hidden_Layer_3'),
    tf.keras.layers.Dense(10, activation='softmax', name='Output_Layer')
])
optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-08,
    name='Adam')
classifier.compile(optimizer=optimizer,
             loss='categorical_crossentropy',
             metrics=['accuracy'])
callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=10)
trained = classifier.fit(encoded_tr_1, y_train, epochs=100, validation_data=(encoded_val,y_val),callbacks=callback)

encoded_val = noisyautoenoder.encoder(val_data).numpy()

loss, mse = classifier.evaluate(encoded_val, y_val)

"""classifer 2

classifier 3
"""

classifier2 = tf.keras.models.Sequential([
    #tf.keras.layers.Flatten(input_shape=(28, 28), name='Input_Layer'),
    tf.keras.layers.Dense(1024, activation='sigmoid', name='Hidden_Layer_1'),
    tf.keras.layers.Dense(512, activation='sigmoid', name='Hidden_Layer_2'),
    tf.keras.layers.Dense(256, activation='sigmoid', name='Hidden_Layer_3'),
    tf.keras.layers.Dense(10, activation='softmax', name='Output_Layer')
])
optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-08,
    name='Adam')
classifier2.compile(optimizer=optimizer,
             loss='categorical_crossentropy',
             metrics=['accuracy'])
callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=10)
trained = classifier2.fit(encoded_tr, y_train, epochs=100, validation_data=(encoded_val,y_val),callbacks=callback)

classifier3 = tf.keras.models.Sequential([
    #tf.keras.layers.Flatten(input_shape=(28, 28), name='Input_Layer'),
    tf.keras.layers.Dense(512, activation='sigmoid', name='Hidden_Layer_1'),
    tf.keras.layers.Dense(256, activation='sigmoid', name='Hidden_Layer_2'),
    tf.keras.layers.Dense(128, activation='sigmoid', name='Hidden_Layer_3'),
    tf.keras.layers.Dense(10, activation='softmax', name='Output_Layer')
])
optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-08,
    name='Adam')
classifier3.compile(optimizer=optimizer,
             loss='categorical_crossentropy',
             metrics=['accuracy'])
callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=10)
trained = classifier3.fit(encoded_tr, y_train, epochs=100, validation_data=(encoded_val,y_val),callbacks=callback)

"""confusion matrix"""

encoded_test = noisyautoenoder.encoder(test_data).numpy()
encoded_val = noisyautoenoder.encoder(val_data).numpy()

"""Confusion matrix validation data"""

prediction_val=classifier3.predict(encoded_val)
from sklearn.metrics import confusion_matrix
#plt.figure(figsize=(16,9))
y_pred_labels=[np.argmax(label) for label in prediction_val]
cm_train=confusion_matrix(val_out,y_pred_labels)
print(cm_train)

"""Confusion matrix test data"""

prediction_val=classifier3.predict(encoded_test)
from sklearn.metrics import confusion_matrix
#plt.figure(figsize=(16,9))
y_pred_labels=[np.argmax(label) for label in prediction_val]
cm_train=confusion_matrix(test_out,y_pred_labels)
print(cm_train)